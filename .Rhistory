# 가로 단위로 계산
apply(df, 2, sum, na.rm=TRUE) # 전체 대상자들의 키, 몸무게의 합
# 첫번째 argument는 벡터, 두번째 argument는 팩터
# df$w를 gender 값으로 grouping하여 값을 내준다.
tapply(1:6, gender, sum, na.rm=TRUE)
mapply(paste, 1:5, LETTERS[1:5], month.abb[1:5])
# 첫번째 argument는 벡터, 두번째 argument는 팩터
# df$w를 gender 값으로 grouping하여 값을 내준다.
tapply(1:6, gender, sum, na.rm=TRUE)
count <- 1
myf <- function(x, wt=T){
print(paste(x,"(",count,")"))
Sys.sleep(5)
if(wt)
r <- paste("*", x, "*")
else
r <- paste("#", x, "#")
count <<- count + 1;
return(r)
}
df
df$w
sapply(df$w, myf)
sapply(df$w, myf, F)
rr1 <- sapply(df$w, myf, wt=F)
rr1
rr1 <- sapply(df$w, myf, wt=F)
df <- data.frame(w=weight, h=height)
apply(df, 1, sum, na.rm=TRUE) # 네번째 이후의 argument들은 필수는아니다.
# 가로 단위로 계산
apply(df, 2, sum, na.rm=TRUE) # 전체 대상자들의 키, 몸무게의 합
?apply
str(rr1)
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(stringr)
useSejongDic()
install.packages("tm")   # textmining
library(tm)
lunch <- c("커피 파스타 치킨 샐러드 아이스크림",
"커피 우동 소고기김밥 귤",
"참치김밥 커피 오뎅",
"샐러드 피자 파스타 콜라",
"티라무슈 햄버거 콜라",
"파스타 샐러드 커피"
)
cps <- VCorpus(VectorSource(lunch))
cps
# TDM, DTM(DocumentTermMatrix) : 누가 괄호에 오느냐가 관건
# TDM은 괄호가 단어, 세로가 도큐먼트.  / DTM은 반대. 도큐먼트가 우선일 때
# 지금은 어떤 음식을 먹었는지 단어가 중요하니 TDM
tdm
# Vector개체를 그냥 쓸 수 없어서 VectorSource를 이용해서 또다른 데이터 구조로 만듦
# 벡터가 가진 원소 개수가 6개 -> documents: 6
tdm <- TermDocumentMatrix(cps)
# TDM, DTM(DocumentTermMatrix) : 누가 괄호에 오느냐가 관건
# TDM은 괄호가 단어, 세로가 도큐먼트.  / DTM은 반대. 도큐먼트가 우선일 때
# 지금은 어떤 음식을 먹었는지 단어가 중요하니 TDM
tdm
# 행이 단어(7행), 열이 도큐먼트(6열)
# 11개만 데이터값이 들어가 있고, 31개는 비어있다.
# 제일 긴 단어길이; 5
# Sparsity?
as.matrix(tdm)
cps <- VCorpus(VectorSource(lunch))
tdm <- TermDocumentMatrix(cps,
control=list(wordLengths = c(1, Inf)))
# Inf
# 문자의 개수 제한이 없도록
tdm
(m <- as.matrix(tdm))
(m <- as.matrix(tdm))
colnames(m) <- c("doc1", "doc2", "doc3", "doc4", "doc5", "doc6")
rowSums(m)
colSums(m)
m
t(m)
com <- m %*% t(m)  # 행렬곱
com
# t()는 행과 열을 바꿔준다.
com
com <- m %*% t(m)  # 행렬곱. 원래의 매트릭스에 행과 열을 바꾼 값을 행렬값 연산.
# t()는 행과 열을 바꿔준다.
com
install.packages("qgraph")
library(qgraph)
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*800))
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*500))
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*800))
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*1000))
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*3000))
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*800))
install.packages("proxy")
library(proxy)
# proxy함수는 유사도분석
dd <- NULL
d1 <- c("aaa bbb ccc")
d2 <- c("aaa bbb ddd")
d3 <- c("aaa bbb ccc")
d4 <- c("xxx yyy zzz")
dd <- c(d1, d2, d3, d4)
cps <- Corpus(VectorSource(dd))
cps
dtm <- DocumentTermMatrix(cps)
dtm
as.matrix(dtm)
inspect(dtm)
com <- m %*% t(m)
com
cps <- Corpus(VectorSource(dd))
dtm <- DocumentTermMatrix(cps) # 가로가 doc 세로가 term
as.matrix(dtm)
inspect(dtm)
m <- as.matrix(dtm)
com <- m %*% t(m)
com
dist(com, method = "cosine")
# dist: distance
# cosine 각도
dist(com, method = "Euclidean")
# 피타고라스
install.packages("lsa")
library(lsa)
cosine(com)
# Install
install.packages("tm")  # 텍스트 마이닝을 위한 패키지
library(lsa)
cosine(com)
# Install
install.packages("tm")  # 텍스트 마이닝을 위한 패키지
install.packages("SnowballC") # 어간추출을 위한 패키지
install.packages("wordcloud") # word-cloud generator
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
stopwords("english"
stopwords("english")
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines(filePath)
# VectorSource () 함수는 문자형 벡터 모음을 만듭니다.
docs <- Corpus(VectorSource(text))
# 텍스트의 특수 문자 등을 대체하기 위해 tm_map () 함수를 사용하여 변환이 수행됩니다.
# “/”,“@”및“|”을 공백으로 바꿉니다.
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
stopwords("english")
듀크 <- c(사과, 포도, 망고)
듀크 <- c("사과 포도 망고")
듀크
둘리 <- c("포도 자몽 자두")
또치 <- c("복숭아 사과 포도")
도우너 <- c("오렌지 바나나 복숭아")
길동 <- c("포도 바나나 망고")
희동 <- c("포도 귤 오렌지")
fruit <- c(듀크, 둘리, 또치, 도우너, 길동, 희동)
fruit
cps <- VCorpus(VectorSource(fruit))
cps
# Vector개체를 그냥 쓸 수 없어서 VectorSource를 이용해서 또다른 데이터 구조로 만듦
# 벡터가 가진 원소 개수가 6개 -> documents: 6
tdm <- TermDocumentMatrix(cps)
tdm
# 행이 단어(7행), 열이 도큐먼트(6열)
# 11개만 데이터값이 들어가 있고, 31개는 비어있다.
# 제일 긴 단어길이; 5
# Sparsity?
as.matrix(tdm)
# Vector개체를 그냥 쓸 수 없어서 VectorSource를 이용해서 또다른 데이터 구조로 만듦
# 벡터가 가진 원소 개수가 6개 -> documents: 6
tdm <- TermDocumentMatrix(cps,
control=list(wordLengths=c(1,Inf)))
# TDM, DTM(DocumentTermMatrix) : 누가 괄호에 오느냐가 관건
# TDM은 괄호가 단어, 세로가 도큐먼트.  / DTM은 반대. 도큐먼트가 우선일 때
# 지금은 어떤 음식을 먹었는지 단어가 중요하니 TDM
tdm
# 행이 단어(7행), 열이 도큐먼트(6열)
# 11개만 데이터값이 들어가 있고, 31개는 비어있다.
# 제일 긴 단어길이; 5
# Sparsity?
as.matrix(tdm)
tdm
m <- as.matrix(tdm)
m
colnames(m) <- c("doc1", "doc2", "doc3", "doc4", "doc5", "doc6")
colnames(m) <- c("doc1", "doc2", "doc3", "doc4", "doc5", "doc6")
rowSums(m) # 어떤 음식을 가장 많이 먹었는지
m
rowSums(m)
max(rowSums(m))
sort(rowSums(m))
sort(rowSums(m), decreasing=T)
library(qgraph)
# 문제 1
colSums(m) # 각 학생이 얼마나 먹었는지
# 문제 1
com <- m %*% t(m)  # 행렬곱. 원래의 매트릭스에 행과 열을 바꾼 값을 행렬값 연산.
# t()는 행과 열을 바꿔준다.
com
library(qgraph)
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*800))
cps <- Corpus(VectorSource(fruit))
cps
dtm <- DocumentTermMatrix(cps) # 가로가 doc 세로가 term
as.matrix(dtm)
inspect(dtm)
m <- as.matrix(dtm)
source('C:/Rstudy/실습제출답안/tm1.R', encoding = 'UTF-8', echo=TRUE)
m
colnames(m) <- c("듀크", "둘리", "또치", "도우너", "길동", "희동동")
rowSums(m)
sort(rowSums(m), decreasing=T)
cps <- Corpus(VectorSource(fruit))
dtm <- DocumentTermMatrix(cps) # 가로가 doc 세로가 term
as.matrix(dtm)
inspect(dtm)
m <- as.matrix(dtm)
m
as.matrix(dtm)
as.matrix(dtm)
m <- as.matrix(dtm)
m
colnames(m) <- c("듀크", "둘리", "또치", "도우너", "길동", "희동")
m
cps <- Corpus(VectorSource(fruit))
fruit
cps <- VCorpus(VectorSource(fruit))
cps
tdm <- TermDocumentMatrix(cps,
control=list(wordLengths=c(1,Inf)))
tdm
as.matrix(tdm)
cps <- Corpus(VectorSource(fruit))
cps
dtm <- DocumentTermMatrix(cps) # 가로가 doc 세로가 term
dtm
cps <- Corpus(VectorSource(fruit))
dtm <- DocumentTermMatrix(cps) # 가로가 doc 세로가 term
dtm
cps
dtm <- DocumentTermMatrix(cps) # 가로가 doc 세로가 term
dtm
tdm
as.matrix(tdm)
com <- m %*% t(m)
com
dist(com, method = "cosine")
# dist: distance
# cosine 각도
dist(com, method = "Euclidean")
cosine(com)
sort(cosine(com))
cosine(com)
str(cosine(com))
max(cosine(com))
unlist(cosine(com))
unlist(cosine(com)) - cosine(com)==1
unlist(cosine(com)) - cosine(com)
cosine(com)
qgraph(com, labels=rownames(com), diag=F,
layout='spring',  edge.color='blue',
vsize=log(diag(com)*800))
cosine(com)
cosine(com)==1 <- NA
cos <- cosine(com)
cos <- cos[!(cos==0)]
cos
cos <- cos[!(cos==1)]
cos
com
cos <- cosine(com)
cos
cos==1
cos[!(cos==1)]
cos==1 <- NA
cos==1 <- "NA"
cos
cos
gsub("1", "***", cos)
cos <- gsub("1", "***", cos)
cos <- gsub("1", "*", cos)
cos
cos <- cosine(com)
cos <- gsub("1", "*", cos)
cos
cos <- cosine(com)
cos
cos <- as.table(cosine(com))
cos
cos <- cos[!(cos==1)]
cos
cos <- as.table(cosine(com))
cos
cos <- cosine(com)
cos
cos <- as.list(cosine(com))
cos
cos <- cosine(com)
cos
install.pacakes("reshape2")
install.packages("reshape2")
library(reshape2)
head(french_fries)
mean(french_fries$potato)
french_fries$potato
mean(french_fries$potato)
french_fries %>% select(potato)
library(dplyr)
french_fries %>% select(potato)
french_fries %>% select(potato) %>% summarise(mean = mean())
french_fries %>% select(potato) %>% summarise(mean = mean(potato)
french_fries %>% select(potato) %>% summarise(mean <- mean(potato))
french_fries %>% select(potato) %>% summarise(mean())
french_fries %>% select(potato)
french_fries %>% select(potato) %>% summarise(mean = mean())
french_fries %>% select(potato) %>% summarise(mean = mean(potato))
str(french_fries)
french_fries %>% select(potato) %>% summarize(평균=mean(potato))
french_fries %>% select(potato) %>% summarize(평균=mean(potato), na.rm=T)
french_fries %>% select(potato) %>% summarize(평균=mean(), na.rm=T)
french_fries %>% select(potato) %>% summarize(평균=mean(potato), na.rm=T)
french_fries %>% select(potato) %>% mean()
mean(french_fries$potato, na.rm=T)
french_fries %>% select(potato) %>% summarise(평균= mean(), na.rm=T)
m %>% group_by(variable) %>% summarize(평균=mean(value, na.rm=T))
m %>% group_by(variable) %>% summarize(평균=mean(value, na.rm=T))
library(dplyr)
m %>% group_by(variable) %>% summarize(평균=mean(value, na.rm=T))
head(french_fries)
library(dplyr)
m %>% group_by(potato) %>% summarize(평균=mean(value, na.rm=T))
head(french_fries)
v
m %>% group_by(variable) %>% summarize(평균=mean(value, na.rm=T))
m2 <- melt(french_fries, id.vars=1:4, na.rm=T)
# 데이터열의 앞에서부터 네번째까지는 안바꾸겠다.
dim(m2)
dim(m)
m2 %>% group_by(variable) %>% summarize(평균=mean(value))
# reshape2: 데이터셋의 구조를 바꿔준다.
library(reshape2)
head(french_fries)
library(dplyr)
m %>% group_by(variable) %>% summarize(평균=mean(value, na.rm=T))
m2 <- melt(french_fries, id.vars=1:4, na.rm=T)
# 데이터열의 앞에서부터 네번째까지는 안바꾸겠다.
dim(m2)
dim(m)
m2 %>% group_by(variable) %>% summarize(평균=mean(value))
r <- dcast(m, time+treatment+subject + rep ~ ...)
# id 해당되는 이름을 엮는다. time~rep까지 사용하고 나머지 값을 갖다붙인다.
# 이때는 variable에 있는 애들이 변수값이 된다.
# decast; metl된 것을 다시 원래대로 되돌리겠다.
head(r)
rownames(r) <- NULL
rownames(french_fries) <- NULL
identical(r, french_fries)
?next
setwd('c:/TrustLevel')
train = read.csv('train.csv', header=T)
head(train)
str(train)
summary(train)
train2 = train[,-c(1,7,28,30,31,32)]
head(train2)
normalize = function(x){
return((x-min(x)) / diff(range(x)))
}
normalize(train2)
result = kmeans(train2, 13)
#군집별 통계
g1 = subset(train3, result$cluster==1)
summary(g1)
#군집별 통계
g1 = subset(train3, result$cluster==1)
#군집별 통계
g1 = subset(train2, result$cluster==1)
summary(g1)
g2 = subset(train2, result2$cluster ==2)
g3 = subset(train2, result2$cluster==3)
summary(g2)
cor(train2[,-27], method="pearson")
cor(mydia[,-5], method="pearson")
library(ggplot2)
t = sample(1:nrow(diamonds),1000) #테스트데이터 뽑기
t
test = diamonds[t,]
dim(test)
test
mydia = test[c("price","carat","depth","table")] #subset 써도 됨
#비계층적 클러스터 구현
result2 = kmeans(mydia,3) #군집수=3
mydia$cluster = result2$cluster
head(mydia)
cor(mydia[,-5], method="pearson")
cor(train2[,-27], method="pearson")
result = kmeans(train2, 5)
names(result)
train2$cluster = result$cluster
head(train2)
#withinss: 집단 내 분산값 betweenss: 집단 간 분산값
km.out.withness = c()
km.out.between = c()
for (i in 2:15){ #r군집수를 k=2~7까지 변화시켜가며
set.seed(1)
km.out = kmeans(train2, centers=i) #i가 1일때 k는 2
km.out.withness[i-1] = km.out$tot.withinss
km.out.between[i-1] = km.out$between
}
data.frame(km.out.withness, km.out.between)
train = read.csv('train.csv', header=T)
train2 = train[,-c(1,7,28,30,31,32)]
normalize = function(x){
return((x-min(x)) / diff(range(x)))
}
normalize(train2)
as.data.frame(sapply(train2,normalize))
train2 = as.data.frame(sapply(train2,normalize))
head(train2)
#withinss: 집단 내 분산값 betweenss: 집단 간 분산값
km.out.withness = c()
km.out.between = c()
for (i in 2:15){ #r군집수를 k=2~7까지 변화시켜가며
set.seed(1)
km.out = kmeans(train2, centers=i) #i가 1일때 k는 2
km.out.withness[i-1] = km.out$tot.withinss
km.out.between[i-1] = km.out$between
}
train2 = train[,-26]
train2 = train2[,-26]
train = read.csv('train.csv', header=T)
train2 = train[,-c(1,7,28,30,31,32)]
normalize = function(x){
return((x-min(x)) / diff(range(x)))
}
train2 = as.data.frame(sapply(train2,normalize))
train2 = as.factor(train2)
train = read.csv('train.csv', header=T)
head(train)
train2 = train[,-c(1,7,28,30,31,32)]
train2 = as.data.frame(sapply(train2,normalize))
train2 = train2[,-26]
head(train2)
#withinss: 집단 내 분산값 betweenss: 집단 간 분산값
km.out.withness = c()
km.out.between = c()
for (i in 2:15){ #r군집수를 k=2~7까지 변화시켜가며
set.seed(1)
km.out = kmeans(train2, centers=i) #i가 1일때 k는 2
km.out.withness[i-1] = km.out$tot.withinss
km.out.between[i-1] = km.out$between
}
data.frame(km.out.withness, km.out.between)
result = kmeans(train2, 3)
names(result)
result
train2$cluster = result$cluster
head(train2)
train$cluster = result$cluster
head(train)
library(dplyr)
train %>% group_by(cluster) %>% summarise(mean(이웃신뢰도))
train %>% group_by(cluster) %>% summarise(mean(가족신뢰도))
train %>% group_by(cluster) %>% summarise(mean(연령))
train %>% group_by(cluster) %>% summarise(mean(종합신뢰도도))
train %>% group_by(cluster) %>% summarise(mean(종합신뢰도))
train %>% group_by(cluster) %>% summarise(mean(공공기관신뢰도))
train %>% group_by(cluster) %>% summarise(mean(종합신뢰도))
train %>% group_by(cluster) %>% summarise(mean(가족신뢰도))
train %>% group_by(cluster) %>% summarise(mean(이웃신뢰도))
train %>% group_by(cluster) %>% summarise(mean(신뢰도))
plot(mydia$carat, mydia$price, col=mydia$cluster)
cor(train2[,-27], method="pearson")
head(train2)
cor(train2[,-26], method="pearson")
train2$cluster
train %>% group_by(cluster) %>% summarise(mean(종합신뢰도))
train %>% group_by(cluster) %>% summarise(mean(가족신뢰도))
train %>% group_by(cluster) %>% summarise(mean(이웃신뢰도))
train %>% group_by(cluster) %>% summarise(mean(공공기관신뢰도))
result
cor(train2[,-26], method="pearson")
plot(train$행복_가정, train$약자_여성, col=train$cluster)
summary(aov(이웃신뢰도 ~ cluster, data = train))
train %>% group_by(cluster) %>% summarise(mean(이웃신뢰도))
train %>%
filter(cluster == 1) %>%
summary()
train %>%
filter(cluster == 2) %>%
summary()
train %>%
filter(cluster == 3) %>%
summary()
